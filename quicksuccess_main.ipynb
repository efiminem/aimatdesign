{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Success: Materials Search with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this quick success is simple, yet an actual implementation may take some time. We are going to write an artificial neural network to predict the materials property and use it to search among existing materials. As a basic library for design the network we will use Torch which is the most convenient neural network environment when the work involves defining new layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our work will be done in Jupyter Notebook, which can contain both computer code (in our case python) and rich text elements (paragraph, equations, figures, links). It is a very flexible tool that helps you create readable analyses and explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells are the primary content of Jupyter notebooks. You can run the cell by clicking on it and executing <code>Ctrl+Enter</code> command. Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick success\n"
     ]
    }
   ],
   "source": [
    "some_string = \"Hello word!\"\n",
    "if \"word\" in some_string:\n",
    "    print(\"Quick success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of files in your current directory should be:\n",
    "\n",
    "- <b>This notebook</b>    \n",
    "    (the main notebook of your project; here you will do all the coding and analytics)    \n",
    "        \n",
    "        \n",
    "- <b>quicksuccess_mining.ipynb</b>    \n",
    "    (data extraction and preparation)\n",
    "    \n",
    "    \n",
    "- <b>quicksuccess_modules.ipynb</b>    \n",
    "    (special layers for the graph neural network)\n",
    "\n",
    "\n",
    "- <b>quicksuccess_net.ipynb</b>    \n",
    "    (graph neural network itself)\n",
    "    \n",
    "    \n",
    "- <b>qucksuccess_train.ipynb</b>    \n",
    "    (necessary functions for training and validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, time\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re-)load modules\n",
    "%run quicksuccess_mining.ipynb\n",
    "%run quicksuccess_modules.ipynb\n",
    "%run quicksuccess_net.ipynb\n",
    "%run quicksuccess_train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick start we will build a convolutional neural network that will be trained on few thousand images of cats and birds, and later be able to predict if the given image is of a cat or a bird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://psv4.userapi.com/c848424/u17311756/docs/d9/d173b2c860c6/dog_bird.gif?extra=40ZGP-NZuQtNkJI7fnsOHPcNvxxKctoNCkPq-7P_zkTFgXPrWcJAq3XN07m5yf1lX5HBw23DP1RTZueWevtriN6oGKuSep_QSs527hLYLsQwg6s9VIbLUBu4TAVnxkjJ9SzmqEAeoL50\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to understand while following this steps is that the model we have built can be trained on any type of data you want. For example, if there are any life scientists reading this, they will be able to build and train neural networks that can take a brain scan as an input and predict if the scan contains a tumour or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFData(root_dir = \"superconductors\",\n",
    "                  max_num_nbr = 12,\n",
    "                  radius=8,\n",
    "                  dmin=0,\n",
    "                  step=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of structures: 291\n",
      "Number of features describing one atom: 92\n",
      "Number of features describing neighbours: 41\n"
     ]
    }
   ],
   "source": [
    "orig_atom_fea_len = dataset[0][0][0].shape[-1]\n",
    "nbr_fea_len = dataset[0][0][1].shape[-1]\n",
    "print(\"Number of structures: {}\".format(len(dataset)))\n",
    "print(\"Number of features describing one atom: {}\".format(orig_atom_fea_len))\n",
    "print(\"Number of features describing neighbours: {}\".format(nbr_fea_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of structures in train set: 203\n",
      "Number of structures in validation set: 88\n"
     ]
    }
   ],
   "source": [
    "train_val_ratio = 0.7\n",
    "indices = list(range(len(dataset)))\n",
    "train_sampler = SubsetRandomSampler(indices[:int(train_val_ratio*len(dataset))])\n",
    "val_sampler = SubsetRandomSampler(indices[int(train_val_ratio*len(dataset)):])\n",
    "train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler, collate_fn=collate_pool)\n",
    "val_loader = DataLoader(dataset, batch_size=16, sampler=val_sampler, collate_fn=collate_pool)\n",
    "print(\"Number of structures in train set: {}\".format(len(train_sampler)))\n",
    "print(\"Number of structures in validation set: {}\".format(len(val_sampler)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0)\n",
    "normalizer = Normalizer(collate_pool(dataset)[1])\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/THCGeneral.cpp:70",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f6b57d2280b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-751d76a61be5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, normalizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         input_var = (input[0].cuda(async=True),\n\u001b[0m\u001b[1;32m     16\u001b[0m                      \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /opt/conda/conda-bld/pytorch_1524584710464/work/aten/src/THC/THCGeneral.cpp:70"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "best_mae_error = 1e10\n",
    "mae_history = []\n",
    "text_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, normalizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        loss_error, mae_error = validate(val_loader, model, criterion, normalizer)\n",
    "\n",
    "        if mae_error != mae_error:\n",
    "            print('Exit due to NaN')\n",
    "            quit()\n",
    "\n",
    "        #scheduler.step()\n",
    "        \n",
    "        #visualize\n",
    "        display.clear_output(wait=True)\n",
    "        if epoch != 0:\n",
    "            mae_history.append(mae_error)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "\n",
    "            plt.title(\"Training\")\n",
    "            plt.xlabel(\"#iteration\")\n",
    "            plt.ylabel(\"MAE\")\n",
    "            plt.plot(range(1, epoch + 1), mae_history, 'b')\n",
    "            plt.show()\n",
    "        text_history.append(\"Epoch: {}\\tLoss: {:.3f}\\tMAE: {:.3f}\".format(epoch + 1, loss_error, mae_error))\n",
    "        print(\"\\n\".join(text_history))\n",
    "\n",
    "        # remember the best mae_eror and save checkpoint\n",
    "        is_best = mae_error < best_mae_error\n",
    "        best_mae_error = min(mae_error, best_mae_error)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_mae_error': best_mae_error,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'normalizer': normalizer.state_dict(),\n",
    "        }, is_best,\n",
    "        filename = 'checkpoint.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal = CIFOne(atom_init_file = \"superconductors/atom_init.json\",\n",
    "                  max_num_nbr = 12,\n",
    "                  radius=8,\n",
    "                  dmin=0,\n",
    "                  step=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "structure = collate_pool([crystal.from_file(\"superconductors/1.cif\")])[0][0]\n",
    "input_var = (structure[0].cuda(async=True),\n",
    "             structure[1].cuda(async=True),\n",
    "             structure[2].cuda(async=True),\n",
    "             [crys_idx.cuda(async=True) for crys_idx in structure[3]])\n",
    "output = model(*input_var)\n",
    "pred_value = normalizer.denorm(output.data.cpu())\n",
    "print(pred_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
