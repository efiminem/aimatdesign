{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Success: Materials Search with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this quick success is simple, yet an actual implementation may take some time. We are going to write an Artificial Neural Network to predict the materials property. As a basic library for design the network we will use Torch which is the most convenient neural network environment when the work involves defining new layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of files in your current directory should be:\n",
    "\n",
    "- This notebook\n",
    "- quicksuccess_mining.ipynb\n",
    "- quicksuccess_modules.ipynb\n",
    "- quicksuccess_net.ipynb\n",
    "- qucksuccess_train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, time\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re-)load modules\n",
    "%run quicksuccess_mining.ipynb\n",
    "%run quicksuccess_modules.ipynb\n",
    "%run quicksuccess_net.ipynb\n",
    "%run quicksuccess_train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFData(root_dir = \"superconductors\",\n",
    "                  max_num_nbr = 12,\n",
    "                  radius=8,\n",
    "                  dmin=0,\n",
    "                  step=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of structures: 291\n",
      "Number of features describing one atom: 92\n",
      "Number of features describing neighbours: 41\n"
     ]
    }
   ],
   "source": [
    "orig_atom_fea_len = dataset[0][0][0].shape[-1]\n",
    "nbr_fea_len = dataset[0][0][1].shape[-1]\n",
    "print(\"Number of structures: {}\".format(len(dataset)))\n",
    "print(\"Number of features describing one atom: {}\".format(orig_atom_fea_len))\n",
    "print(\"Number of features describing neighbours: {}\".format(nbr_fea_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_list = [dataset[i] for i in range(len(dataset))]\n",
    "_, sample_target, _ = collate_pool(sample_data_list)\n",
    "normalizer = Normalizer(sample_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "train_val_ratio = 0.7\n",
    "train_sampler = SubsetRandomSampler(indices[:int(train_val_ratio*len(dataset))])\n",
    "val_sampler = SubsetRandomSampler(indices[int(train_val_ratio*len(dataset)):])\n",
    "train_loader = DataLoader(dataset, batch_size=64,\n",
    "                          sampler=train_sampler,\n",
    "                          collate_fn=collate_pool)\n",
    "val_loader = DataLoader(dataset, batch_size=64,\n",
    "                        sampler=val_sampler,\n",
    "                        collate_fn=collate_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrystalGraphConvNet(\n",
       "  (embedding): Linear(in_features=92, out_features=64, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (2): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (3): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (4): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (5): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (6): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (7): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (8): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (9): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (10): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (11): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (12): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (13): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (14): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (15): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (16): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (17): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (18): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (19): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (20): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (21): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (22): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (23): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (24): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (25): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (26): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (27): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (28): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (29): ConvLayer(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "  )\n",
       "  (conv_to_fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (conv_to_fc_softplus): Softplus(beta=1, threshold=20)\n",
       "  (fcs): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (softpluses): ModuleList(\n",
       "    (0): Softplus(beta=1, threshold=20)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "    (2): Softplus(beta=1, threshold=20)\n",
       "    (3): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CrystalGraphConvNet(orig_atom_fea_len, nbr_fea_len)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0)\n",
    "#normalizer = Normalizer(torch.zeros(1))\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100], gamma=0.1)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3718],\n",
      "        [ 1.3097],\n",
      "        [ 0.7810],\n",
      "        [-0.0731],\n",
      "        [-0.8381],\n",
      "        [-0.7009],\n",
      "        [-0.2357],\n",
      "        [-1.1305],\n",
      "        [ 0.7378],\n",
      "        [-0.0375],\n",
      "        [-0.5331],\n",
      "        [-0.9347],\n",
      "        [ 0.0184],\n",
      "        [ 2.3366],\n",
      "        [ 1.5258],\n",
      "        [ 0.4709],\n",
      "        [ 0.0057],\n",
      "        [-0.7746],\n",
      "        [ 1.6427],\n",
      "        [ 1.3097],\n",
      "        [ 1.0758],\n",
      "        [-0.9780],\n",
      "        [-0.0019],\n",
      "        [-0.5484],\n",
      "        [-0.5484],\n",
      "        [ 0.6641],\n",
      "        [ 0.1125],\n",
      "        [ 0.0540],\n",
      "        [-0.9957],\n",
      "        [ 0.2777],\n",
      "        [-0.0095],\n",
      "        [-0.8864],\n",
      "        [ 0.2447],\n",
      "        [ 2.9466],\n",
      "        [ 0.3870],\n",
      "        [-0.4670],\n",
      "        [ 2.9339],\n",
      "        [ 2.9339],\n",
      "        [-0.0731],\n",
      "        [ 0.3489],\n",
      "        [-0.8229],\n",
      "        [ 0.0972],\n",
      "        [ 0.1277],\n",
      "        [ 0.1735],\n",
      "        [-0.4543],\n",
      "        [-1.0567],\n",
      "        [-0.8763],\n",
      "        [-0.3298],\n",
      "        [ 0.1277],\n",
      "        [-0.6068],\n",
      "        [-1.1305],\n",
      "        [-0.6577],\n",
      "        [-1.0847],\n",
      "        [-1.0618],\n",
      "        [-0.9957],\n",
      "        [-1.1813],\n",
      "        [ 0.8217],\n",
      "        [-1.2626],\n",
      "        [-0.2510],\n",
      "        [ 0.4455],\n",
      "        [-0.4035],\n",
      "        [-0.7848],\n",
      "        [-0.2510],\n",
      "        [-0.4594]])\n",
      "tensor([[-0.8026],\n",
      "        [-0.3552],\n",
      "        [-0.3018],\n",
      "        [-1.1305],\n",
      "        [-0.5738],\n",
      "        [-1.2220],\n",
      "        [ 0.0159],\n",
      "        [-0.1264],\n",
      "        [ 2.9288],\n",
      "        [-0.7161],\n",
      "        [-1.2067],\n",
      "        [ 0.2447],\n",
      "        [ 2.6543],\n",
      "        [-1.1076],\n",
      "        [ 0.7352],\n",
      "        [-0.1798],\n",
      "        [-0.6856],\n",
      "        [ 2.7382],\n",
      "        [-0.0731],\n",
      "        [-0.6373],\n",
      "        [-0.6577],\n",
      "        [ 1.3758],\n",
      "        [-0.0324],\n",
      "        [-0.1290],\n",
      "        [-0.1112],\n",
      "        [-0.5840],\n",
      "        [ 0.3870],\n",
      "        [-0.9551],\n",
      "        [ 0.0795],\n",
      "        [-0.1493],\n",
      "        [-1.1813],\n",
      "        [-0.7466],\n",
      "        [ 0.2015],\n",
      "        [-0.5763],\n",
      "        [-0.5636],\n",
      "        [-1.1813],\n",
      "        [-0.4467],\n",
      "        [-1.1076],\n",
      "        [-0.7670],\n",
      "        [-0.7314],\n",
      "        [ 0.6158],\n",
      "        [-1.2753],\n",
      "        [-0.1061],\n",
      "        [-0.8763],\n",
      "        [ 0.6463],\n",
      "        [-0.1519],\n",
      "        [ 0.9310],\n",
      "        [ 0.5802],\n",
      "        [ 0.3616],\n",
      "        [ 0.2015],\n",
      "        [ 1.6859],\n",
      "        [-0.0985],\n",
      "        [-1.1813],\n",
      "        [-0.9449],\n",
      "        [-0.0527],\n",
      "        [ 2.0240],\n",
      "        [-0.0731],\n",
      "        [ 1.0835],\n",
      "        [ 0.8039],\n",
      "        [ 0.2726],\n",
      "        [-0.7009],\n",
      "        [ 0.0489],\n",
      "        [-0.5738],\n",
      "        [ 2.9187]])\n",
      "tensor([[ 0.0210],\n",
      "        [ 1.0098],\n",
      "        [-0.6678],\n",
      "        [-0.0451],\n",
      "        [-0.8864],\n",
      "        [-0.3425],\n",
      "        [-0.6907],\n",
      "        [ 0.4353],\n",
      "        [ 0.1252],\n",
      "        [-0.7670],\n",
      "        [ 0.6793],\n",
      "        [-0.4543],\n",
      "        [ 0.2980],\n",
      "        [-0.3222],\n",
      "        [-0.4975],\n",
      "        [-0.1290],\n",
      "        [ 0.4455],\n",
      "        [-0.2662],\n",
      "        [-0.8381],\n",
      "        [ 0.3235],\n",
      "        [ 1.1394],\n",
      "        [-0.1036],\n",
      "        [ 0.4861],\n",
      "        [ 1.6859],\n",
      "        [ 0.2447],\n",
      "        [ 0.0972],\n",
      "        [-0.7390],\n",
      "        [-0.8712],\n",
      "        [-0.9373],\n",
      "        [ 0.9742],\n",
      "        [-0.1112],\n",
      "        [-1.1305],\n",
      "        [ 0.6285],\n",
      "        [ 0.4811],\n",
      "        [ 0.6437],\n",
      "        [ 2.9568],\n",
      "        [ 0.2472],\n",
      "        [-0.5890],\n",
      "        [-0.6424],\n",
      "        [-0.7390],\n",
      "        [-0.7314],\n",
      "        [ 2.9111],\n",
      "        [ 0.7073],\n",
      "        [ 0.2320],\n",
      "        [ 1.1318],\n",
      "        [-0.4925],\n",
      "        [ 2.6848],\n",
      "        [-0.6704],\n",
      "        [ 0.6793],\n",
      "        [-0.9347],\n",
      "        [-1.0796],\n",
      "        [ 0.0159],\n",
      "        [ 0.1888],\n",
      "        [-0.6704],\n",
      "        [ 0.0922],\n",
      "        [-0.2967],\n",
      "        [ 0.4531],\n",
      "        [ 1.6071],\n",
      "        [-0.4162],\n",
      "        [ 0.9742],\n",
      "        [ 1.7901],\n",
      "        [ 0.8318],\n",
      "        [ 0.3743],\n",
      "        [ 0.2498]])\n",
      "tensor([[ 0.4734],\n",
      "        [-0.4975],\n",
      "        [-0.6068],\n",
      "        [-1.1305],\n",
      "        [ 0.9233],\n",
      "        [ 1.0504],\n",
      "        [-0.8763],\n",
      "        [ 0.0337],\n",
      "        [-1.0517],\n",
      "        [-0.0756],\n",
      "        [ 0.0667]])\n"
     ]
    }
   ],
   "source": [
    "for i, (input, target, _) in enumerate(train_loader):\n",
    "    input_var = (input[0].cuda(async=True),\n",
    "                 input[1].cuda(async=True),\n",
    "                 input[2].cuda(async=True),\n",
    "                 [crys_idx.cuda(async=True) for crys_idx in input[3]])\n",
    "    target_normed = normalizer.norm(target)\n",
    "    target_var = target_normed.cuda(async=True)\n",
    "    print(target_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/4]\tTime 1.086 (1.086)\tData 0.002 (0.002)\tLoss 0.9072 (0.9072)\tMAE 0.312 (0.312)\n",
      "Epoch: [0][1/4]\tTime 0.426 (0.756)\tData 0.003 (0.003)\tLoss 2.4832 (1.6952)\tMAE 0.450 (0.381)\n",
      "Epoch: [0][2/4]\tTime 0.358 (0.623)\tData 0.003 (0.003)\tLoss 3.2841 (2.2248)\tMAE 0.657 (0.473)\n",
      "Epoch: [0][3/4]\tTime 0.115 (0.496)\tData 0.001 (0.002)\tLoss 1.4124 (2.1808)\tMAE 0.413 (0.470)\n",
      "Test: [0/2]\tTime 0.048 (0.048)\tLoss 77.1034 (77.1034)\tMAE 3.420 (3.420)\n",
      " *\t Loss 77.7557 \t MAE 3.439\n",
      "Epoch: [1][0/4]\tTime 0.359 (0.359)\tData 0.002 (0.002)\tLoss 0.9852 (0.9852)\tMAE 0.284 (0.284)\n",
      "Epoch: [1][1/4]\tTime 0.374 (0.367)\tData 0.003 (0.003)\tLoss 2.7863 (1.8857)\tMAE 0.602 (0.443)\n",
      "Epoch: [1][2/4]\tTime 0.344 (0.359)\tData 0.003 (0.003)\tLoss 1.2784 (1.6833)\tMAE 0.317 (0.401)\n",
      "Epoch: [1][3/4]\tTime 0.082 (0.290)\tData 0.001 (0.002)\tLoss 0.5262 (1.6206)\tMAE 0.234 (0.392)\n",
      "Test: [0/2]\tTime 0.047 (0.047)\tLoss 1.3342 (1.3342)\tMAE 0.275 (0.275)\n",
      " *\t Loss 1.3533 \t MAE 0.283\n",
      "Epoch: [2][0/4]\tTime 0.356 (0.356)\tData 0.002 (0.002)\tLoss 0.7428 (0.7428)\tMAE 0.253 (0.253)\n",
      "Epoch: [2][1/4]\tTime 0.341 (0.348)\tData 0.003 (0.002)\tLoss 1.1072 (0.9250)\tMAE 0.316 (0.285)\n",
      "Epoch: [2][2/4]\tTime 0.376 (0.357)\tData 0.003 (0.002)\tLoss 0.9444 (0.9315)\tMAE 0.318 (0.296)\n",
      "Epoch: [2][3/4]\tTime 0.085 (0.289)\tData 0.001 (0.002)\tLoss 1.8739 (0.9825)\tMAE 0.369 (0.300)\n",
      "Test: [0/2]\tTime 0.047 (0.047)\tLoss 1.2900 (1.2900)\tMAE 0.276 (0.276)\n",
      " *\t Loss 1.1255 \t MAE 0.261\n",
      "Epoch: [3][0/4]\tTime 0.349 (0.349)\tData 0.002 (0.002)\tLoss 1.0555 (1.0555)\tMAE 0.314 (0.314)\n",
      "Epoch: [3][1/4]\tTime 0.400 (0.375)\tData 0.003 (0.002)\tLoss 0.8944 (0.9750)\tMAE 0.309 (0.311)\n",
      "Epoch: [3][2/4]\tTime 0.339 (0.363)\tData 0.002 (0.002)\tLoss 1.1705 (1.0401)\tMAE 0.300 (0.308)\n",
      "Epoch: [3][3/4]\tTime 0.075 (0.291)\tData 0.001 (0.002)\tLoss 0.6796 (1.0206)\tMAE 0.276 (0.306)\n",
      "Test: [0/2]\tTime 0.047 (0.047)\tLoss 0.7782 (0.7782)\tMAE 0.238 (0.238)\n",
      " *\t Loss 1.0910 \t MAE 0.268\n",
      "Epoch: [4][0/4]\tTime 0.342 (0.342)\tData 0.002 (0.002)\tLoss 1.0743 (1.0743)\tMAE 0.314 (0.314)\n",
      "Epoch: [4][1/4]\tTime 0.287 (0.314)\tData 0.002 (0.002)\tLoss 0.6911 (0.8827)\tMAE 0.254 (0.284)\n",
      "Epoch: [4][2/4]\tTime 0.445 (0.358)\tData 0.003 (0.002)\tLoss 0.9432 (0.9029)\tMAE 0.275 (0.281)\n",
      "Epoch: [4][3/4]\tTime 0.098 (0.293)\tData 0.001 (0.002)\tLoss 1.6024 (0.9408)\tMAE 0.407 (0.288)\n",
      "Test: [0/2]\tTime 0.048 (0.048)\tLoss 1.2304 (1.2304)\tMAE 0.347 (0.347)\n",
      " *\t Loss 1.2497 \t MAE 0.350\n"
     ]
    }
   ],
   "source": [
    "best_mae_error = 1e10\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, normalizer)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        mae_error = validate(val_loader, model, criterion, normalizer)\n",
    "\n",
    "        if mae_error != mae_error:\n",
    "            print('Exit due to NaN')\n",
    "            quit()\n",
    "\n",
    "        #scheduler.step()\n",
    "\n",
    "        # remember the best mae_eror and save checkpoint\n",
    "        is_best = mae_error < best_mae_error\n",
    "        best_mae_error = min(mae_error, best_mae_error)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_mae_error': best_mae_error,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'normalizer': normalizer.state_dict(),\n",
    "        }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(np.arange(len(loss_save)), loss_save)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
