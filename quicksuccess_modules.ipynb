{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional operation on graphs\n",
    "    \"\"\"\n",
    "    def __init__(self, atom_fea_len, nbr_fea_len):\n",
    "        \"\"\"\n",
    "        Initialize ConvLayer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        atom_fea_len: int\n",
    "          Number of atom hidden features.\n",
    "        nbr_fea_len: int\n",
    "          Number of bond features.\n",
    "        \"\"\"\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.atom_fea_len = atom_fea_len\n",
    "        self.nbr_fea_len = nbr_fea_len\n",
    "        self.fc_full = nn.Linear(2*self.atom_fea_len+self.nbr_fea_len,\n",
    "                                 2*self.atom_fea_len)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softplus1 = nn.Softplus()\n",
    "        self.bn1 = nn.BatchNorm1d(2*self.atom_fea_len)\n",
    "        self.bn2 = nn.BatchNorm1d(self.atom_fea_len)\n",
    "        self.softplus2 = nn.Softplus()\n",
    "\n",
    "    def forward(self, atom_in_fea, nbr_fea, nbr_fea_idx):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        N: Total number of atoms in the batch\n",
    "        M: Max number of neighbors\n",
    "        Parameters\n",
    "        ----------\n",
    "        atom_in_fea: Variable(torch.Tensor) shape (N, atom_fea_len)\n",
    "          Atom hidden features before convolution\n",
    "        nbr_fea: Variable(torch.Tensor) shape (N, M, nbr_fea_len)\n",
    "          Bond features of each atom's M neighbors\n",
    "        nbr_fea_idx: torch.LongTensor shape (N, M)\n",
    "          Indices of M neighbors of each atom\n",
    "        Returns\n",
    "        -------\n",
    "        atom_out_fea: nn.Variable shape (N, atom_fea_len)\n",
    "          Atom hidden features after convolution\n",
    "        \"\"\"\n",
    "        # TODO will there be problems with the index zero padding?\n",
    "        N, M = nbr_fea_idx.shape\n",
    "        # convolution\n",
    "        atom_nbr_fea = atom_in_fea[nbr_fea_idx, :]\n",
    "        total_nbr_fea = torch.cat(\n",
    "            [atom_in_fea.unsqueeze(1).expand(N, M, self.atom_fea_len),\n",
    "             atom_nbr_fea, nbr_fea], dim=2)\n",
    "        total_gated_fea = self.fc_full(total_nbr_fea)\n",
    "        total_gated_fea = self.bn1(total_gated_fea.view(\n",
    "            -1, self.atom_fea_len*2)).view(N, M, self.atom_fea_len*2)\n",
    "        nbr_filter, nbr_core = total_gated_fea.chunk(2, dim=2)\n",
    "        nbr_filter = self.sigmoid(nbr_filter)\n",
    "        nbr_core = self.softplus1(nbr_core)\n",
    "        nbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\n",
    "        nbr_sumed = self.bn2(nbr_sumed)\n",
    "        out = self.softplus2(atom_in_fea + nbr_sumed)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
