{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(prediction, target):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error between prediction and target\n",
    "    Parameters\n",
    "    ----------\n",
    "    prediction: torch.Tensor (N, 1)\n",
    "    target: torch.Tensor (N, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(target - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, cuda = True):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        if cuda == True:\n",
    "            input_var = (input[0].cuda(async=True),\n",
    "                         input[1].cuda(async=True),\n",
    "                         input[2].cuda(async=True),\n",
    "                         [crys_idx.cuda(async=True) for crys_idx in input[3]])\n",
    "        else:\n",
    "            input_var = (input[0],\n",
    "                         input[1],\n",
    "                         input[2],\n",
    "                         [crys_idx for crys_idx in input[3]])\n",
    "        # normalize target\n",
    "        target_normed = target\n",
    "        if cuda == True:\n",
    "            target_var = target_normed.cuda(async=True)\n",
    "        else:\n",
    "            target_var = target_normed\n",
    "\n",
    "        # compute output\n",
    "        output = model(*input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(output.data.cpu(), target)\n",
    "        losses.update(loss.data.cpu().item(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        return losses.avg, mae_errors.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, test=False, cuda = True):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "    if test:\n",
    "        test_targets = []\n",
    "        test_preds = []\n",
    "        test_cif_ids = []\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, batch_cif_ids) in enumerate(val_loader):\n",
    "        if cuda == True:\n",
    "            input_var = (input[0].cuda(async=True),\n",
    "                         input[1].cuda(async=True),\n",
    "                         input[2].cuda(async=True),\n",
    "                         [crys_idx.cuda(async=True) for crys_idx in input[3]])\n",
    "        else:\n",
    "             input_var = (input[0],\n",
    "                         input[1],\n",
    "                         input[2],\n",
    "                         [crys_idx for crys_idx in input[3]])\n",
    "        target_normed = target\n",
    "        if cuda == True:\n",
    "            target_var = target_normed.cuda(async=True)\n",
    "        else:\n",
    "             target_var = target_normed\n",
    "\n",
    "        # compute output\n",
    "        output = model(*input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(output.data.cpu(), target)\n",
    "        losses.update(loss.data.cpu().item(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "        if test:\n",
    "            test_pred = normalizer.denorm(output.data.cpu())\n",
    "            test_target = target\n",
    "            test_preds += test_pred.view(-1).tolist()\n",
    "            test_targets += test_target.view(-1).tolist()\n",
    "            test_cif_ids += batch_cif_ids\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    return losses.avg, mae_errors.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_graph_training(model, train_loader, val_loader, n_epochs = 50, lr=0.01, cuda = True):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9, weight_decay=0)\n",
    "    \n",
    "    best_mae_error = 1e10\n",
    "    best_mae_epoch = 0\n",
    "    mae_history = []\n",
    "    text_history = []\n",
    "    train_mae = []\n",
    "    val_mae = []\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "            # train for one epoch\n",
    "            loss_error, mae_error = train(train_loader, model, criterion, optimizer, epoch, cuda)\n",
    "            train_mae.append(mae_error)\n",
    "\n",
    "            # evaluate on validation set\n",
    "            loss_error, mae_error = validate(val_loader, model, criterion, False, cuda)\n",
    "            val_mae.append(mae_error)\n",
    "\n",
    "            if mae_error != mae_error:\n",
    "                print('Exit due to NaN')\n",
    "                quit()\n",
    "                \n",
    "            if mae_error < best_mae_error:\n",
    "                best_mae_error = mae_error\n",
    "                best_mae_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            #visualize\n",
    "            display.clear_output(wait=True)\n",
    "            plt.plot(np.arange(len(train_mae)) + 1, train_mae, label = 'MAE on train dataset')\n",
    "            plt.plot(np.arange(len(val_mae)) + 1, val_mae, label = 'MAE on val dataset')\n",
    "            print(\"MAE on train dataset now: \", float(train_mae[-1]))\n",
    "            print(\"MAE on val dataset now: \", float(val_mae[-1]))\n",
    "            print(\"best MAE on val dataset up to now: \", float(best_mae_error))\n",
    "            print(\"best MAE on val dataset was in epoch number: \", int(best_mae_epoch))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    return best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
