{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "    def __init__(self, tensor):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = torch.mean(tensor)\n",
    "        self.std = torch.std(tensor)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(prediction, target):\n",
    "    \"\"\"\n",
    "    Computes the mean absolute error between prediction and target\n",
    "    Parameters\n",
    "    ----------\n",
    "    prediction: torch.Tensor (N, 1)\n",
    "    target: torch.Tensor (N, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean(torch.abs(target - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, normalizer):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input_var = (input[0].cuda(async=True),\n",
    "                     input[1].cuda(async=True),\n",
    "                     input[2].cuda(async=True),\n",
    "                     [crys_idx.cuda(async=True) for crys_idx in input[3]])\n",
    "        # normalize target\n",
    "        target_normed = normalizer.norm(target)\n",
    "        target_var = target_normed.cuda(async=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(*input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "        losses.update(loss.data.cpu().item(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "              'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\n",
    "               epoch, i, len(train_loader), batch_time=batch_time,\n",
    "               data_time=data_time, loss=losses, mae_errors=mae_errors)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, normalizer, test=False):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mae_errors = AverageMeter()\n",
    "    if test:\n",
    "        test_targets = []\n",
    "        test_preds = []\n",
    "        test_cif_ids = []\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target, batch_cif_ids) in enumerate(val_loader):\n",
    "        input_var = (input[0].cuda(async=True),\n",
    "                     input[1].cuda(async=True),\n",
    "                     input[2].cuda(async=True),\n",
    "                     [crys_idx.cuda(async=True) for crys_idx in input[3]])\n",
    "        target_normed = normalizer.norm(target)\n",
    "        target_var = target_normed.cuda(async=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(*input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        mae_error = mae(normalizer.denorm(output.data.cpu()), target)\n",
    "        losses.update(loss.data.cpu().item(), target.size(0))\n",
    "        mae_errors.update(mae_error, target.size(0))\n",
    "        if test:\n",
    "            test_pred = normalizer.denorm(output.data.cpu())\n",
    "            test_target = target\n",
    "            test_preds += test_pred.view(-1).tolist()\n",
    "            test_targets += test_target.view(-1).tolist()\n",
    "            test_cif_ids += batch_cif_ids\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'MAE {mae_errors.val:.3f} ({mae_errors.avg:.3f})'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       mae_errors=mae_errors))\n",
    "\n",
    "    if test:\n",
    "        star_label = '**'\n",
    "        import csv\n",
    "        with open('test_results.csv', 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for cif_id, target, pred in zip(test_cif_ids, test_targets,\n",
    "                                            test_preds):\n",
    "                writer.writerow((cif_id, target, pred))\n",
    "    else:\n",
    "        star_label = '*'\n",
    "    print(' {star}\\t Loss {loss.avg:.4f} \\t MAE {mae_errors.avg:.3f}'.format(star=star_label, loss=losses,\n",
    "                                                    mae_errors=mae_errors))\n",
    "    return mae_errors.avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
